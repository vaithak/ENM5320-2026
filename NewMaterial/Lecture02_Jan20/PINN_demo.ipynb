{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54b1c621",
   "metadata": {},
   "source": [
    "# Physics-Informed Neural Networks (PINNs)\n",
    "## Solving PDEs with Deep Learning\n",
    "\n",
    "This notebook demonstrates how to implement Physics-Informed Neural Networks (PINNs) for solving partial differential equations.\n",
    "\n",
    "**Key Idea:** Train a neural network to satisfy:\n",
    "1. The PDE itself (physics loss)\n",
    "2. Initial and boundary conditions (data loss)\n",
    "\n",
    "**Advantages:**\n",
    "- Mesh-free method\n",
    "- Can handle high-dimensional problems\n",
    "- Incorporates physical laws directly into the loss function\n",
    "- Automatic differentiation provides derivatives\n",
    "\n",
    "**Example Problem:** 1D Heat Equation\n",
    "$$\\frac{\\partial u}{\\partial t} = \\alpha \\frac{\\partial^2 u}{\\partial x^2}, \\quad x \\in [0,1], \\, t \\in [0,T]$$\n",
    "\n",
    "with boundary conditions: $u(0,t) = u(1,t) = 0$\n",
    "\n",
    "and initial condition: $u(x,0) = \\sin(\\pi x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c761341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Set device and precision\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_dtype(torch.float64)\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Default dtype: {torch.get_default_dtype()}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0097773",
   "metadata": {},
   "source": [
    "## Define the Neural Network Architecture\n",
    "\n",
    "The network takes $(x, t)$ as input and outputs $u(x,t)$.\n",
    "\n",
    "We use a fully connected feedforward network with multiple hidden layers and tanh activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427490bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    \"\"\"\n",
    "    Physics-Informed Neural Network for solving PDEs.\n",
    "    \n",
    "    Architecture: Fully connected network with tanh activations\n",
    "    Input: (x, t) coordinates\n",
    "    Output: u(x, t) solution\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        layers : list of int\n",
    "            Number of neurons in each layer\n",
    "            Example: [2, 50, 50, 50, 1] for input(x,t) -> 3 hidden layers -> output u\n",
    "        \"\"\"\n",
    "        super(PINN, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(layers) - 1):\n",
    "            self.layers.append(nn.Linear(layers[i], layers[i+1]))\n",
    "            \n",
    "    def forward(self, x, t):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        x : torch.Tensor\n",
    "            Spatial coordinates\n",
    "        t : torch.Tensor\n",
    "            Time coordinates\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        u : torch.Tensor\n",
    "            Network output (solution prediction)\n",
    "        \"\"\"\n",
    "        # Concatenate inputs\n",
    "        inputs = torch.cat([x, t], dim=1)\n",
    "        \n",
    "        # Pass through hidden layers with tanh activation\n",
    "        out = inputs\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            out = torch.tanh(self.layers[i](out))\n",
    "        \n",
    "        # Final layer (no activation)\n",
    "        out = self.layers[-1](out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Initialize network\n",
    "layers = [2, 50, 50, 50, 1]  # 2 inputs (x,t), 3 hidden layers with 50 neurons, 1 output (u)\n",
    "model = PINN(layers).to(device)\n",
    "\n",
    "print(f\"Network architecture: {layers}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86522b2a",
   "metadata": {},
   "source": [
    "## Automatic Differentiation for Computing PDE Residuals\n",
    "\n",
    "PyTorch's autograd allows us to compute derivatives of the network output with respect to inputs.\n",
    "\n",
    "For the heat equation, we need:\n",
    "- $\\frac{\\partial u}{\\partial t}$: time derivative\n",
    "- $\\frac{\\partial^2 u}{\\partial x^2}$: second spatial derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee410c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pde_residual(model, x, t, alpha):\n",
    "    \"\"\"\n",
    "    Compute the PDE residual: du/dt - alpha * d²u/dx²\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : nn.Module\n",
    "        The PINN model\n",
    "    x : torch.Tensor\n",
    "        Spatial coordinates (requires_grad=True)\n",
    "    t : torch.Tensor\n",
    "        Time coordinates (requires_grad=True)\n",
    "    alpha : float\n",
    "        Thermal diffusivity coefficient\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    residual : torch.Tensor\n",
    "        PDE residual at each point\n",
    "    \"\"\"\n",
    "    # Enable gradient computation\n",
    "    x.requires_grad_(True)\n",
    "    t.requires_grad_(True)\n",
    "    \n",
    "    # Forward pass\n",
    "    u = model(x, t)\n",
    "    \n",
    "    # Compute first derivatives\n",
    "    u_t = torch.autograd.grad(\n",
    "        u, t,\n",
    "        grad_outputs=torch.ones_like(u),\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0]\n",
    "    \n",
    "    u_x = torch.autograd.grad(\n",
    "        u, x,\n",
    "        grad_outputs=torch.ones_like(u),\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0]\n",
    "    \n",
    "    # Compute second spatial derivative\n",
    "    u_xx = torch.autograd.grad(\n",
    "        u_x, x,\n",
    "        grad_outputs=torch.ones_like(u_x),\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0]\n",
    "    \n",
    "    # PDE residual: du/dt - alpha * d²u/dx²\n",
    "    residual = u_t - alpha * u_xx\n",
    "    \n",
    "    return residual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4874a8",
   "metadata": {},
   "source": [
    "## Generate Training Data\n",
    "\n",
    "We need:\n",
    "1. **Collocation points**: Random points in the domain for PDE residual\n",
    "2. **Boundary points**: Points on boundaries $x=0$ and $x=1$\n",
    "3. **Initial condition points**: Points at $t=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e510482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain parameters\n",
    "x_min, x_max = 0.0, 1.0\n",
    "t_min, t_max = 0.0, 1.0\n",
    "alpha = 0.05  # Thermal diffusivity\n",
    "\n",
    "# Number of training points\n",
    "N_collocation = 10000  # Interior points for PDE\n",
    "N_boundary = 100       # Boundary points\n",
    "N_initial = 100        # Initial condition points\n",
    "\n",
    "# Collocation points (random points in domain)\n",
    "x_collocation = torch.rand(N_collocation, 1, device=device) * (x_max - x_min) + x_min\n",
    "t_collocation = torch.rand(N_collocation, 1, device=device) * (t_max - t_min) + t_min\n",
    "\n",
    "# Boundary points: x = 0 and x = 1 for all t\n",
    "t_boundary = torch.rand(N_boundary, 1, device=device) * (t_max - t_min) + t_min\n",
    "x_boundary_0 = torch.zeros(N_boundary, 1, device=device)\n",
    "x_boundary_1 = torch.ones(N_boundary, 1, device=device)\n",
    "u_boundary = torch.zeros(N_boundary, 1, device=device)  # u = 0 at boundaries\n",
    "\n",
    "# Initial condition points: t = 0 for all x\n",
    "x_initial = torch.rand(N_initial, 1, device=device) * (x_max - x_min) + x_min\n",
    "t_initial = torch.zeros(N_initial, 1, device=device)\n",
    "u_initial = torch.sin(np.pi * x_initial)  # u(x,0) = sin(πx)\n",
    "\n",
    "print(f\"Collocation points: {N_collocation}\")\n",
    "print(f\"Boundary points: {2 * N_boundary}\")\n",
    "print(f\"Initial condition points: {N_initial}\")\n",
    "print(f\"Total training points: {N_collocation + 2*N_boundary + N_initial}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faf3bc6",
   "metadata": {},
   "source": [
    "## Visualize Training Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d283444",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot collocation points (sample for visibility)\n",
    "sample_size = 500\n",
    "ax.scatter(x_collocation[:sample_size].cpu(), t_collocation[:sample_size].cpu(), \n",
    "           s=1, c='blue', alpha=0.3, label='Collocation (PDE)')\n",
    "\n",
    "# Plot boundary points\n",
    "ax.scatter(x_boundary_0.cpu(), t_boundary.cpu(), \n",
    "           s=10, c='red', marker='s', label='Boundary x=0')\n",
    "ax.scatter(x_boundary_1.cpu(), t_boundary.cpu(), \n",
    "           s=10, c='orange', marker='s', label='Boundary x=1')\n",
    "\n",
    "# Plot initial condition points\n",
    "ax.scatter(x_initial.cpu(), t_initial.cpu(), \n",
    "           s=10, c='green', marker='^', label='Initial condition')\n",
    "\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('t', fontsize=12)\n",
    "ax.set_title('Training Points Distribution', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183c68c2",
   "metadata": {},
   "source": [
    "## Define the Loss Function\n",
    "\n",
    "The total loss is a weighted sum of:\n",
    "1. **PDE loss**: $\\mathcal{L}_{PDE} = \\frac{1}{N_{col}} \\sum |\\text{PDE residual}|^2$\n",
    "2. **Boundary loss**: $\\mathcal{L}_{BC} = \\frac{1}{N_{bc}} \\sum |u_{pred} - u_{bc}|^2$\n",
    "3. **Initial condition loss**: $\\mathcal{L}_{IC} = \\frac{1}{N_{ic}} \\sum |u_{pred} - u_{ic}|^2$\n",
    "\n",
    "$$\\mathcal{L}_{total} = \\lambda_{PDE} \\mathcal{L}_{PDE} + \\lambda_{BC} \\mathcal{L}_{BC} + \\lambda_{IC} \\mathcal{L}_{IC}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f2894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(model, x_col, t_col, \n",
    "                  x_bc0, x_bc1, t_bc, u_bc,\n",
    "                  x_ic, t_ic, u_ic,\n",
    "                  alpha, lambda_pde=1.0, lambda_bc=1.0, lambda_ic=1.0):\n",
    "    \"\"\"\n",
    "    Compute the total PINN loss.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : nn.Module\n",
    "        The PINN model\n",
    "    x_col, t_col : torch.Tensor\n",
    "        Collocation points for PDE residual\n",
    "    x_bc0, x_bc1, t_bc, u_bc : torch.Tensor\n",
    "        Boundary condition points and values\n",
    "    x_ic, t_ic, u_ic : torch.Tensor\n",
    "        Initial condition points and values\n",
    "    alpha : float\n",
    "        PDE parameter (thermal diffusivity)\n",
    "    lambda_pde, lambda_bc, lambda_ic : float\n",
    "        Loss weights\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    loss : torch.Tensor\n",
    "        Total loss\n",
    "    losses_dict : dict\n",
    "        Dictionary with individual loss components\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. PDE residual loss\n",
    "    residual = compute_pde_residual(model, x_col, t_col, alpha)\n",
    "    loss_pde = torch.mean(residual ** 2)\n",
    "    \n",
    "    # 2. Boundary condition loss\n",
    "    u_pred_bc0 = model(x_bc0, t_bc)\n",
    "    u_pred_bc1 = model(x_bc1, t_bc)\n",
    "    loss_bc = torch.mean((u_pred_bc0 - u_bc) ** 2) + torch.mean((u_pred_bc1 - u_bc) ** 2)\n",
    "    \n",
    "    # 3. Initial condition loss\n",
    "    u_pred_ic = model(x_ic, t_ic)\n",
    "    loss_ic = torch.mean((u_pred_ic - u_ic) ** 2)\n",
    "    \n",
    "    # Total loss\n",
    "    loss = lambda_pde * loss_pde + lambda_bc * loss_bc + lambda_ic * loss_ic\n",
    "    \n",
    "    losses_dict = {\n",
    "        'total': loss.item(),\n",
    "        'pde': loss_pde.item(),\n",
    "        'bc': loss_bc.item(),\n",
    "        'ic': loss_ic.item()\n",
    "    }\n",
    "    \n",
    "    return loss, losses_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c44b6b",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eb5611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 5000\n",
    "print_every = 500\n",
    "\n",
    "# Loss weights\n",
    "lambda_pde = 1.0\n",
    "lambda_bc = 100.0  # Higher weight for boundary conditions\n",
    "lambda_ic = 100.0  # Higher weight for initial conditions\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=500, verbose=True\n",
    ")\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'total': [],\n",
    "    'pde': [],\n",
    "    'bc': [],\n",
    "    'ic': []\n",
    "}\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Epochs: {num_epochs}\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "print(f\"Loss weights - PDE: {lambda_pde}, BC: {lambda_bc}, IC: {lambda_ic}\")\n",
    "print()\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Compute loss\n",
    "    loss, losses_dict = loss_function(\n",
    "        model, x_collocation, t_collocation,\n",
    "        x_boundary_0, x_boundary_1, t_boundary, u_boundary,\n",
    "        x_initial, t_initial, u_initial,\n",
    "        alpha, lambda_pde, lambda_bc, lambda_ic\n",
    "    )\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step(loss)\n",
    "    \n",
    "    # Store history\n",
    "    for key in history.keys():\n",
    "        history[key].append(losses_dict[key])\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % print_every == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "              f\"Total: {losses_dict['total']:.6e} | \"\n",
    "              f\"PDE: {losses_dict['pde']:.6e} | \"\n",
    "              f\"BC: {losses_dict['bc']:.6e} | \"\n",
    "              f\"IC: {losses_dict['ic']:.6e} | \"\n",
    "              f\"Time: {elapsed:.2f}s\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTraining completed in {total_time:.2f} seconds\")\n",
    "print(f\"Final loss: {history['total'][-1]:.6e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22a117b",
   "metadata": {},
   "source": [
    "## Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0cdc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot total loss\n",
    "axes[0].semilogy(history['total'], 'b-', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Total Loss', fontsize=12)\n",
    "axes[0].set_title('Total Loss vs Epoch', fontsize=14)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot individual losses\n",
    "axes[1].semilogy(history['pde'], label='PDE', linewidth=2)\n",
    "axes[1].semilogy(history['bc'], label='Boundary', linewidth=2)\n",
    "axes[1].semilogy(history['ic'], label='Initial', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Loss Component', fontsize=12)\n",
    "axes[1].set_title('Loss Components vs Epoch', fontsize=14)\n",
    "axes[1].legend(fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b2385e",
   "metadata": {},
   "source": [
    "## Evaluate the Trained Model\n",
    "\n",
    "Create a fine grid and evaluate the PINN solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035f86c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluation grid\n",
    "n_x = 100\n",
    "n_t = 100\n",
    "\n",
    "x_eval = np.linspace(x_min, x_max, n_x)\n",
    "t_eval = np.linspace(t_min, t_max, n_t)\n",
    "X_eval, T_eval = np.meshgrid(x_eval, t_eval)\n",
    "\n",
    "# Flatten for network input\n",
    "x_test = torch.tensor(X_eval.flatten()[:, None], device=device)\n",
    "t_test = torch.tensor(T_eval.flatten()[:, None], device=device)\n",
    "\n",
    "# Evaluate model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    u_pred = model(x_test, t_test).cpu().numpy()\n",
    "\n",
    "U_pred = u_pred.reshape(n_t, n_x)\n",
    "\n",
    "print(f\"Evaluation grid: {n_x} x {n_t} points\")\n",
    "print(f\"Solution range: [{U_pred.min():.6f}, {U_pred.max():.6f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bc05de",
   "metadata": {},
   "source": [
    "## Analytical Solution\n",
    "\n",
    "For the given problem, the analytical solution is:\n",
    "$$u(x,t) = e^{-\\alpha \\pi^2 t} \\sin(\\pi x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe137ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute analytical solution\n",
    "U_exact = np.exp(-alpha * np.pi**2 * T_eval) * np.sin(np.pi * X_eval)\n",
    "\n",
    "# Compute error\n",
    "error = np.abs(U_pred - U_exact)\n",
    "relative_error = np.linalg.norm(U_pred - U_exact) / np.linalg.norm(U_exact)\n",
    "\n",
    "print(f\"L2 relative error: {relative_error:.6e}\")\n",
    "print(f\"Max absolute error: {error.max():.6e}\")\n",
    "print(f\"Mean absolute error: {error.mean():.6e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501a380",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08a7ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 5))\n",
    "\n",
    "# PINN solution\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "surf1 = ax1.plot_surface(X_eval, T_eval, U_pred, cmap='viridis', alpha=0.9)\n",
    "ax1.set_xlabel('x', fontsize=10)\n",
    "ax1.set_ylabel('t', fontsize=10)\n",
    "ax1.set_zlabel('u(x,t)', fontsize=10)\n",
    "ax1.set_title('PINN Solution', fontsize=12)\n",
    "fig.colorbar(surf1, ax=ax1, shrink=0.5)\n",
    "\n",
    "# Analytical solution\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "surf2 = ax2.plot_surface(X_eval, T_eval, U_exact, cmap='viridis', alpha=0.9)\n",
    "ax2.set_xlabel('x', fontsize=10)\n",
    "ax2.set_ylabel('t', fontsize=10)\n",
    "ax2.set_zlabel('u(x,t)', fontsize=10)\n",
    "ax2.set_title('Analytical Solution', fontsize=12)\n",
    "fig.colorbar(surf2, ax=ax2, shrink=0.5)\n",
    "\n",
    "# Error\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "surf3 = ax3.plot_surface(X_eval, T_eval, error, cmap='hot', alpha=0.9)\n",
    "ax3.set_xlabel('x', fontsize=10)\n",
    "ax3.set_ylabel('t', fontsize=10)\n",
    "ax3.set_zlabel('|error|', fontsize=10)\n",
    "ax3.set_title('Absolute Error', fontsize=12)\n",
    "fig.colorbar(surf3, ax=ax3, shrink=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1105c83",
   "metadata": {},
   "source": [
    "## 2D Comparison: Contour Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f1ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# PINN solution\n",
    "im1 = axes[0].contourf(X_eval, T_eval, U_pred, levels=20, cmap='viridis')\n",
    "axes[0].set_xlabel('x', fontsize=12)\n",
    "axes[0].set_ylabel('t', fontsize=12)\n",
    "axes[0].set_title('PINN Solution', fontsize=14)\n",
    "fig.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Analytical solution\n",
    "im2 = axes[1].contourf(X_eval, T_eval, U_exact, levels=20, cmap='viridis')\n",
    "axes[1].set_xlabel('x', fontsize=12)\n",
    "axes[1].set_ylabel('t', fontsize=12)\n",
    "axes[1].set_title('Analytical Solution', fontsize=14)\n",
    "fig.colorbar(im2, ax=axes[1])\n",
    "\n",
    "# Error\n",
    "im3 = axes[2].contourf(X_eval, T_eval, error, levels=20, cmap='hot')\n",
    "axes[2].set_xlabel('x', fontsize=12)\n",
    "axes[2].set_ylabel('t', fontsize=12)\n",
    "axes[2].set_title('Absolute Error', fontsize=14)\n",
    "fig.colorbar(im3, ax=axes[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f22615",
   "metadata": {},
   "source": [
    "## Time Slices Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15567154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot solution at different time points\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "time_indices = [0, 19, 39, 59, 79, 99]\n",
    "\n",
    "for idx, t_idx in enumerate(time_indices):\n",
    "    ax = axes[idx]\n",
    "    t = t_eval[t_idx]\n",
    "    \n",
    "    ax.plot(x_eval, U_pred[t_idx, :], 'b-', linewidth=2, label='PINN')\n",
    "    ax.plot(x_eval, U_exact[t_idx, :], 'r--', linewidth=2, label='Analytical')\n",
    "    ax.set_xlabel('x', fontsize=10)\n",
    "    ax.set_ylabel('u(x,t)', fontsize=10)\n",
    "    ax.set_title(f't = {t:.3f}', fontsize=12)\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim([-0.1, 1.1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32c9c2c",
   "metadata": {},
   "source": [
    "## Check PDE Residual on Test Points\n",
    "\n",
    "Evaluate how well the trained network satisfies the PDE on unseen points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b5df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test points\n",
    "N_test = 1000\n",
    "x_test_pde = torch.rand(N_test, 1, device=device) * (x_max - x_min) + x_min\n",
    "t_test_pde = torch.rand(N_test, 1, device=device) * (t_max - t_min) + t_min\n",
    "\n",
    "# Compute residual\n",
    "model.eval()\n",
    "residual_test = compute_pde_residual(model, x_test_pde, t_test_pde, alpha)\n",
    "residual_test_np = residual_test.detach().cpu().numpy()\n",
    "\n",
    "print(f\"PDE residual statistics on {N_test} test points:\")\n",
    "print(f\"  Mean: {residual_test_np.mean():.6e}\")\n",
    "print(f\"  Std: {residual_test_np.std():.6e}\")\n",
    "print(f\"  Max absolute: {np.abs(residual_test_np).max():.6e}\")\n",
    "print(f\"  RMS: {np.sqrt(np.mean(residual_test_np**2)):.6e}\")\n",
    "\n",
    "# Plot residual distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(residual_test_np, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('PDE Residual', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Distribution of PDE Residuals', fontsize=14)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "scatter = axes[1].scatter(x_test_pde.cpu(), t_test_pde.cpu(), \n",
    "                          c=np.abs(residual_test_np), s=20, cmap='hot')\n",
    "axes[1].set_xlabel('x', fontsize=12)\n",
    "axes[1].set_ylabel('t', fontsize=12)\n",
    "axes[1].set_title('Absolute PDE Residual in Domain', fontsize=14)\n",
    "fig.colorbar(scatter, ax=axes[1], label='|Residual|')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5371ef6e",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### What we accomplished:\n",
    "1. ✅ Built a PINN architecture for solving PDEs\n",
    "2. ✅ Used automatic differentiation to compute PDE residuals\n",
    "3. ✅ Combined physics loss with data loss (BCs and ICs)\n",
    "4. ✅ Trained the network successfully\n",
    "5. ✅ Validated against analytical solution\n",
    "\n",
    "### Advantages of PINNs:\n",
    "- Mesh-free: No need to discretize the domain explicitly\n",
    "- Flexible: Can handle complex geometries and irregular domains\n",
    "- Incorporates physics: The PDE is enforced during training\n",
    "- Differentiable: Can compute derivatives analytically via autograd\n",
    "\n",
    "### Limitations and challenges:\n",
    "- Training can be slow and may require careful tuning\n",
    "- Loss balancing between different terms is crucial\n",
    "- May struggle with sharp gradients or discontinuities\n",
    "- No guarantee of convergence to the correct solution\n",
    "\n",
    "### Extensions:\n",
    "1. **Harder PDEs**: Navier-Stokes, wave equation, etc.\n",
    "2. **Inverse problems**: Learn unknown PDE parameters from data\n",
    "3. **Multi-fidelity**: Combine low and high-fidelity data\n",
    "4. **Adaptive sampling**: Focus training points where error is large\n",
    "5. **Neural operators**: Learn solution operators instead of individual solutions\n",
    "6. **Higher dimensions**: 2D, 3D spatial domains\n",
    "7. **Complex geometries**: Non-rectangular domains with curved boundaries"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
